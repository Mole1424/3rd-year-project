\chapter{Design \& Implementation}
\label{ch:design-implementation}

\section{Language \& Libraries}

% \begin{itemize}
%     \item Python as pre-existing machine learning frameworks
%     \item Tensorflow vs PyTorch (Tensorflow seemed nicer and more base code, first code seen for proof of concept was in tensorflow)
%     \item mutually exclusive due to CUDA implementations
% \end{itemize}

\subsection{Python}

When choosing a language to code this project in Python\footnote{\url{https://www.python.org}} was a clear choice. Whilst other languages offer better speed (C++\footnote{\url{https://cplusplus.com/}}, Rust\footnote{\url{https://www.rust-lang.org/}}), Python's advantage comes from its libraries.

Libraries are modular pieces of code written by other developers that can be integrated into a new software to make common tasks easier. In Python this is accomplished using the \verb|import| and \verb|from| syntax. Libraries vastly simplify coding as they can vastly reduce complex problems to simple functions. This is especially useful when dealing with complex machine learning functions, advanced mathematical algorithms such as Adam can be reduced to an import (Listing \ref{lst:adam}). Many Python libraries are written in lower-level languages like C or C++, allowing Python code to benefit from high performance while maintaining ease of use.

\begin{listing}[H]
    \begin{minted}{python}
        from some_ml_library import adam
        model.optimize(adam)
    \end{minted}
    \caption{An example of Python's import feature to simplify machine learning algorithms such as the Adam optimiser}
    \label{lst:adam}
\end{listing}

The vast majority of popular packages have a Python implementation that can be easily installed by the Python Package Index\footnote{\url{https://pypi.org/}}. Especially for machine learning, Python has some of the largest collection of relevant libraries of any language and is therefore the language of choice for this project.

\subsection{PyTorch versus TensorFlow}

There are many machine learning frameworks in Python, however the primary two are PyTorch\cite{paszke2019pytorch} and TensorFlow\cite{abadi2016tensorflow}. They both offer near identical feature sets and performance so choosing between them is not a simple matter.

PyTorch was created by Meta in 2019. It is a lot newer and viewed as a more ``pythonic" framework\cite{chirodea2021comparison}. To be more ``pythonic" is to be more developer-friendlier by providing a simple interface to the library that developers already familiar with Python should easily pick up on. PyTorch supports a dynamic computation graph which enables for dynamic changes of model architectures.

TensorFlow is a much more mature framework by Google releasing in 2015. It offers similar abstractions as PyTorch but is widely viewed to be slightly harder to develop in\cite{chirodea2021comparison}. TensorFlow uses an eager computation graph meaning no changes to model architectures can be made once a model is defined. Whilst this reduces flexibility during runtime, it allows for more optimisations to be made to the model architecture meaning greater accuracy, smaller model architectures, and sometimes quicker computations. TensorFlow also scales effectively running as efficiently as possible on desktop computers to large GPU clusters.

Unfortunately, TensorFlow and PyTorch are mutually exclusive. Both rely on separate versions of the CUDA backend to allow for GPU acceleration on NVIDIA architectures. Whilst this can be accomplished using virtually environments and other work arounds it is generally recommended to use one or the other.

Due to their similarities, there is no clear choice between PyTorch and TensorFlow. Some trends have emerged, however, with PyTorch being used for research and development work where iterative improvements are desired whereas as TensorFlow is employed for production environments. 

TensorFlow was chosen for this project for a number of reasons. Firstly, the flexibility that PyTorch offers is less important to this project as all models being used have had their architectures pre-defined. On the other hand, TensorFlow's ability to scale and optimise for the compute resources will be valuable for this project as it will be developed on smaller desktops but the final evaluation loops will be run on large GPU clusters. Furthermore, after trying out both TensorFlow and PyTorch, the author preferred the overall syntax of TensorFlow.

\section{Proof of Concept}

\begin{itemize}
    \item Re-use oriented design
    \item Quick and dirty
    \item Test my theory
    \item Explain methodologies
\end{itemize}

\section{Main Algorithm}

\begin{itemize}
    \item pseudocode of main algorithm
    \item if at any point something fails, mark as fake (ensures resiliency)
    \item emphasise each part is interchangeable
\end{itemize}

\subsection{Eye Landmark Detection}

\begin{itemize}
    \item EAR needs 6 points per eye so lets get them
    \item Facial landmarking is a common superset problem
    \item Introduce 68 landmarks and datasets
    \item Most popular ones aren't viable as built to be small to fit in a package (dlib, opencv...) or to run on a phone (mediapipe)
\end{itemize}

\subsubsection{Face cropping}

YuNet for first pass, MTCNN if yunet fails

\subsubsection{Weakly Supervised Eye Landmarks Detection (WSELD)}

\begin{itemize}
    \item Looked promising
    \item Most accurate according to landmarks in paper \& only model focussing specifically on eye landmarking
    \item Has a ``good enough" implementation details
    \item Had issues
    \begin{itemize}
        \item Landmarks from regions (mention other paper that managed it
        \item difficulty implementing in tensorflow
        \item after a month scrapped development
    \end{itemize}
\end{itemize}

\subsubsection{Pre-implemented Models}

\begin{itemize}
    \item Re-use oriented design
    \item papers with code
    \item Used best models which had pre-existing implementations (one for fast, one more accurate)
    \item couldve optimised for 6 landmarks but didnt want to mess with model architectures that were known working (batch size probably meant nothing would change anyway)
\end{itemize}

\subsubsection{HRNet}

\begin{itemize}
    \item modular sequences
    \item keeps high resolution layers in context at all times
    \item generic network but with a specific implementation for eye landmarking
    \item Heatmap per landmark
\end{itemize}

\subsubsection{PFLD}

\begin{itemize}
    \item speedy boi
    \item uses mobilenet-techniques to reduce the size and increase the speed
    \item still accurate tho
    \item secret sauce is custom loss function
\end{itemize}

\subsubsection{Facial Landmark Datasets}

\begin{itemize}
    \item 68 landmarks (upsampling and downsampling where necessary)
    \item list all of them and give brief overview
    \item didnt use aflw due to inaccurate landmarks or not enough landmarks
    \item reflected to double size
\end{itemize}

\subsubsection{Final model choice}

Yunet + PFLD, then MTCNN and HRNET as backup (hope ear analysis can filter out idiosyncrasies of the model as will be consistent across real and fake)

\subsection{EAR Analysis}

\begin{itemize}
    \item Can be abstracted to a univariate time series
    \item Well researched
    \item Classical methods exists (pyts library)
    \item explain each one and give simple summary (1 paragraph)
    \item As do deep learning frameworks (the other papers)
    \item model diagrams for each one (maybe give a rough explenation as to the aims each one is doing?)
\end{itemize}

\section{Adversarial Noise}

\begin{itemize}
    \item foolbox library (Targeted FGSM using the other thing)
    \item chosen over cleverhans as cleverhans had meh documentation
    \item cw-l2 attack too slow (3hrs per video)
    \item fakeretouch has no open-source implementation, timings were too slow, estimated would also take a while
\end{itemize}

\section{DeepFake Datasets}
\label{sec:datasets}

\section{Final Code}

\begin{itemize}
    \item One codebase to do full training, splitting and evaluation
    \item just give overall flow diagram?
    \item {\huge models only trained on non-noisy images}
    \item checkpointing where possible
    \item run on either dcs compute clusters or avon
    \item final speeds + hardware
\end{itemize}